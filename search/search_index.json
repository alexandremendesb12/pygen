{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83e\udde0 Bem-vindo \u00e0 Documenta\u00e7\u00e3o do PyGen","text":"<p>PyGen \u00e9 uma biblioteca interna desenvolvida para padronizar e acelerar os processos de engenharia de dados e machine learning dentro da Genesis.</p> <p>Este portal foi criado com MkDocs + Material for MkDocs e serve como refer\u00eancia oficial para os recursos da biblioteca.</p>"},{"location":"#principais-recursos","title":"\u2728 Principais Recursos","text":"<ul> <li>\ud83d\udce6 SparkSession customizada para ambientes locais, cloud e Databricks</li> <li>\ud83e\udde0 AutoLogMixin: logging autom\u00e1tico de m\u00e9todos</li> <li>\ud83d\udcca FeatureEngineering base com leitura validada de dados (Delta/Parquet)</li> <li>\ud83d\udd04 Integra\u00e7\u00f5es futuras com MLflow, Airflow, etc.</li> </ul>"},{"location":"#estrutura-da-documentacao","title":"\ud83d\udcc4 Estrutura da Documenta\u00e7\u00e3o","text":"<ul> <li><code>Logger</code>: Como usar o logger com cores, contexto e n\u00edveis.</li> <li><code>SparkSession</code>: Inicializa\u00e7\u00e3o de sess\u00f5es Spark port\u00e1veis.</li> <li><code>FeatureEngineering</code>: Classe base para transforma\u00e7\u00e3o de dados.</li> </ul>"},{"location":"#como-contribuir","title":"\ud83e\udd1d Como Contribuir","text":"<p>Voc\u00ea pode contribuir com a documenta\u00e7\u00e3o de forma colaborativa! Basta acessar a aba <code>Docs Contributing</code> e seguir os passos recomendados!</p>"},{"location":"docs_contributing/","title":"\ud83d\udcda Sobre a Documenta\u00e7\u00e3o da PyGen","text":"<p>Este portal de documenta\u00e7\u00e3o foi constru\u00eddo com MkDocs utilizando o tema Material, com o objetivo de organizar, padronizar e facilitar o uso dos recursos oferecidos pela biblioteca PyGen.</p>"},{"location":"docs_contributing/#objetivos","title":"\u2728 Objetivos","text":"<ul> <li>Documentar os principais componentes da lib (loggers, mixins, sessions, etc.)</li> <li>Servir como refer\u00eancia r\u00e1pida para quem est\u00e1 utilizando ou integrando PyGen</li> <li>Tornar o conhecimento acess\u00edvel para engenharia de dados e machine learning</li> </ul>"},{"location":"docs_contributing/#como-contribuir","title":"\u270d\ufe0f Como Contribuir","text":"<ol> <li> <p>Fa\u00e7a checkout do reposit\u00f3rio e crie uma branch:    <code>bash    git checkout -b docs/melhoria-exemplo</code></p> </li> <li> <p>Edite ou crie arquivos <code>.md</code> dentro da pasta <code>/docs</code>.</p> </li> <li> <p>Visualize localmente:    <code>bash    mkdocs serve</code></p> </li> <li> <p>Gere o build final:    <code>bash    mkdocs build</code></p> </li> <li> <p>Envie seu PR com as altera\u00e7\u00f5es documentadas.</p> </li> </ol>"},{"location":"docs_contributing/#boas-praticas","title":"\ud83d\udca1 Boas pr\u00e1ticas","text":"<ul> <li>Use linguagem clara e objetiva</li> <li>Adicione exemplos sempre que poss\u00edvel</li> <li>Atualize a navega\u00e7\u00e3o no <code>mkdocs.yml</code> se criar novas p\u00e1ginas</li> </ul>"},{"location":"feature_engineering/","title":"\ud83e\udde0 FeatureEngineering Base Class","text":"<p><code>FeatureEngineering</code> is a foundational class for managing data loading, transformation logic, and reuse across feature pipelines. It extends <code>AutoLogMixin</code> for automatic logging and includes a ready-to-use SparkSession.</p>"},{"location":"feature_engineering/#features","title":"\ud83d\udd27 Features","text":"<ul> <li>Auto-managed SparkSession</li> <li>Safe and validated dataset loading</li> <li>Format support: Delta, Parquet</li> <li>Layered path abstraction (e.g., bronze/silver/gold)</li> <li>Logging of entry/exit and exceptions via <code>AutoLogMixin</code></li> </ul>"},{"location":"feature_engineering/#initialization","title":"\ud83e\uddf1 Initialization","text":"<pre><code>from pygen.core.engineering.feature_engineering import FeatureEngineering\n\nquery = \"\"\"\n    SELECT \n        id,\n        name,\n        age\n    FROM \n        customers.accounts.profile\n\"\"\" \n\nclass MyFeature(FeatureEngineering):\n    def __init__():\n        super().__init__()\n\n    def process():\n        df = self.load_table(\"customers\", layer=\"silver\")\n        query_df = self.run_query(query)\n\n        return df.join(query, on=\"id\", how=\"inner\")\n</code></pre>"},{"location":"feature_engineering/#methods","title":"\ud83e\udde9 Methods","text":""},{"location":"feature_engineering/#load_tabletable-str-layer-optionalstr-none-format-str-delta","title":"<code>load_table(table: str, layer: Optional[str] = None, format: str = \"delta\")</code>","text":"<p>Loads a dataset by combining the layer and table path, and validates supported formats.</p>"},{"location":"feature_engineering/#run_queryquery-str","title":"<code>run_query(query: str)</code>","text":"<p>Loads data using SQL query and return a spark dataframe.</p>"},{"location":"feature_engineering/#_read_datapath-str-format-str-delta","title":"<code>_read_data(path: str, format: str = \"delta\")</code>","text":"<p>Internal method for direct path-based reading with validation and error handling.</p>"},{"location":"feature_engineering/#error-handling","title":"\u26a0\ufe0f Error Handling","text":"<ul> <li>Raises <code>ValueError</code> for unsupported formats.</li> <li>Raises <code>RuntimeError</code> with descriptive message if dataset can't be read.</li> </ul>"},{"location":"logger/","title":"\ud83d\udcd8 Genesis Logger Documentation","text":""},{"location":"logger/#overview","title":"Overview","text":"<p>The <code>Logger</code> module provides a standardized and enhanced logging system with: - Colored log levels for better visibility in terminal outputs. - Contextual logging that includes the logger name. - Automatic logging of method calls (entry, exit, errors) via the <code>AutoLogMixin</code>.</p> <p>This utility is ideal for logging in both data engineering and machine learning pipelines with minimal boilerplate.</p>"},{"location":"logger/#features","title":"\u2728 Features","text":"<ul> <li>ANSI-colored logs for better readability in CLI environments.</li> <li>Automatic logging of public method calls (<code>AutoLogMixin</code>) \u2014 no need to manually decorate methods.</li> <li>Safe and extensible architecture using Python\u2019s <code>logging</code>, <code>inspect</code>, and <code>functools</code> libraries.</li> </ul>"},{"location":"logger/#components","title":"\ud83d\udce6 Components","text":""},{"location":"logger/#logger-class","title":"<code>Logger</code> class","text":"<pre><code>logger = Logger(name=\"MyService\", level=\"DEBUG\").get()\n</code></pre>"},{"location":"logger/#parameters","title":"Parameters:","text":"Parameter Type Description <code>name</code> <code>str</code> Logger name shown in log messages <code>level</code> <code>str</code> Logging level (<code>DEBUG</code>, <code>INFO</code>, etc.)"},{"location":"logger/#methods","title":"Methods:","text":"<ul> <li><code>get()</code> \u2013 Returns the configured <code>logging.Logger</code> instance.</li> </ul>"},{"location":"logger/#output-format","title":"Output Format:","text":"<pre><code>[2025-04-23 12:00:00] [DEBUG] [MyService] - Message here\n</code></pre>"},{"location":"logger/#coloredformatter-class","title":"<code>ColoredFormatter</code> class","text":"<p>A custom formatter that injects ANSI escape codes to color the log level names.</p>"},{"location":"logger/#example","title":"Example:","text":"<ul> <li><code>DEBUG</code>: Blue</li> <li><code>INFO</code>: Green</li> <li><code>WARNING</code>: Yellow</li> <li><code>ERROR</code>: Red</li> <li><code>CRITICAL</code>: Magenta</li> </ul>"},{"location":"logger/#auto_loglogger-function","title":"<code>auto_log(logger)</code> function","text":"<p>A decorator factory that returns a decorator which: - Logs method/function entry (with arguments) - Logs return value on exit - Logs exceptions and stack traces if an error occurs</p>"},{"location":"logger/#usage","title":"Usage:","text":"<pre><code>@auto_log(logger)\ndef my_function(x, y):\n    return x + y\n</code></pre>"},{"location":"logger/#autologmixin-class","title":"<code>AutoLogMixin</code> class","text":"<p>A mixin that automatically applies the <code>auto_log</code> decorator to all public instance methods of a class that has a <code>self.logger</code> attribute.</p>"},{"location":"logger/#usage_1","title":"Usage:","text":"<pre><code>class MyComponent(AutoLogMixin):\n    def __init__(self):\n        self.logger = Logger(\"MyComponent\", \"DEBUG\").get()\n        super().__init__()\n\n    def process(self, data):\n        return [d * 2 for d in data]\n</code></pre>"},{"location":"logger/#behavior","title":"Behavior:","text":"<ul> <li>Automatically wraps all methods that:</li> <li>Don\u2019t start with <code>_</code></li> <li>Are callable</li> <li>Are instance-bound methods (not static or class methods)</li> </ul>"},{"location":"logger/#output-with-colors","title":"\u2705 Output (with colors):","text":"<pre><code>[2025-04-23 12:00:00] [DEBUG] [MyComponent] - Entering: process | args=(...), kwargs={}\n[2025-04-23 12:00:00] [DEBUG] [MyComponent] - Exiting: process | return=[...]\n</code></pre>"},{"location":"logger/#best-practices","title":"\ud83d\udca1 Best Practices","text":"<ul> <li>Always call <code>super().__init__()</code> when using <code>AutoLogMixin</code>.</li> <li>Use descriptive logger names (e.g., <code>ETLStep1</code>, <code>ModelTrainer</code>) for traceability.</li> </ul>"},{"location":"logger/#example-full-usage","title":"\ud83d\udcce Example Full Usage","text":"<pre><code>class MyService(AutoLogMixin):\n    def __init__(self):\n        self.logger = Logger(\"MyService\", \"DEBUG\").get()\n        super().__init__()\n\n    def add(self, a, b):\n        return a + b\n\ns = MyService()\ns.add(2, 3)\n</code></pre>"},{"location":"spark_session/","title":"\ud83d\ude80 PyGen SparkSession","text":"<p>The <code>SparkSession</code> class is a standardized and portable wrapper around <code>pyspark.sql.SparkSession</code>, designed to simplify and unify the Spark initialization process across local, cloud, and Databricks environments.</p>"},{"location":"spark_session/#features","title":"\u2728 Features","text":"<ul> <li>Loads external YAML configs</li> <li>Custom tags for observability (e.g., lineage, team, env)</li> <li>Predefined defaults for shuffle partitions and timezone</li> <li>Compatible with Delta Lake, Parquet, and more</li> <li>Logging with contextual info</li> </ul>"},{"location":"spark_session/#initialization","title":"\ud83e\uddf1 Initialization","text":"<pre><code>from pygen.infra.service.spark.spark_session import SparkSession\n\nspark = SparkSession(\n    app_name=\"MyApp\",\n    tags={\"env\": \"dev\", \"owner\": \"ds-team\"}\n)\ndf = spark.read.parquet(\"path/to/file.parquet\")\n</code></pre>"},{"location":"spark_session/#configuration","title":"\u2699\ufe0f Configuration","text":"<ul> <li>If <code>configs/spark_defaults.yaml</code> exists, it's automatically loaded.</li> <li>You can override configs using the <code>tags</code>, <code>app_name</code>, or YAML file.</li> <li>Tags are added as <code>spark.genesis.tag.{key}</code> Spark properties.</li> </ul>"},{"location":"spark_session/#output-example-logs","title":"\ud83d\udce4 Output Example (logs)","text":"<pre><code>[INFO] SparkSession initialized - App: MyApp\n[INFO] Spark version: 3.x.x\n[INFO] Applied tags: {'env': 'dev', 'owner': 'ds-team'}\n</code></pre>"},{"location":"spark_session/#methods","title":"\ud83e\udde9 Methods","text":""},{"location":"spark_session/#__getattr__","title":"<code>__getattr__</code>","text":"<p>Delegates method access to the underlying SparkSession instance.</p>"},{"location":"spark_session/#_create_spark_session","title":"<code>_create_spark_session</code>","text":"<p>Builds a configured Spark session.</p>"},{"location":"spark_session/#_load_external_configs","title":"<code>_load_external_configs</code>","text":"<p>Safely loads Spark configs from a YAML file.</p>"}]}